{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef894d13-534e-4c12-b745-df41d2632a6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import re\n",
    "import string\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2aa6419-be39-41d5-a251-f27ff28f4269",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('resfe_df_delivery_mode_2024-02-23.csv')\n",
    "data_cleaned = df.copy(deep=True)\n",
    "\n",
    "data_cleaned.drop(columns='elective_emergency',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21058e6f-48cb-42e2-898c-f28d1c231355",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to preprocess text\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(f'[{re.escape(string.punctuation)}]', '', text)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cff4db65-2981-48cf-81a9-a8b4c5df1a43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preprocess the text data and split the dataset\n",
    "data_cleaned['preprocessed_text'] = data_cleaned['diagnosis'].apply(preprocess_text)\n",
    "X = data_cleaned.drop(columns=['delivery_mode_NVD', 'diagnosis'])\n",
    "y = data_cleaned['delivery_mode_NVD']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Extract and preprocess numerical features\n",
    "numerical_features = X_train.drop(columns=['preprocessed_text', 'patient_id'])  # Adjust as necessary\n",
    "numerical_features_test = X_test.drop(columns=['preprocessed_text', 'patient_id'])  # Adjust as necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70ea3756-2ea8-4abc-9c52-d4f188d31268",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "int_cols=['age', 'hb', 'ga_weeks','kg_upd','height_upd','bmi','abortion','living_children','parity','gravida','upd_cervix_length','upd_afi','efw_upd' ]\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the numerical columns of the training data and transform\n",
    "numerical_features[int_cols] = scaler.fit_transform(numerical_features[int_cols])\n",
    "\n",
    "# Transform the numerical columns of the test data using the same scaler\n",
    "numerical_features_test[int_cols] = scaler.transform(numerical_features_test[int_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f358af62-7e60-411a-889b-8d8bbec5db69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dmis-lab/biobert-v1.1...\n",
      "torch.Size([255, 30, 3878])\n",
      "torch.Size([64, 30, 3878])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define a function to preprocess text\n",
    "def preprocess_text(text):\n",
    "    # Your preprocessing code here\n",
    "    return processed_text\n",
    "\n",
    "bert_model = \"dmis-lab/biobert-v1.1\"\n",
    "# # Assuming X contains features and y contains labels\n",
    "# X = data_cleaned.drop(columns=['delivery_mode_NVD', 'diagnosis'])\n",
    "# y = data_cleaned['delivery_mode_NVD']\n",
    "# # Split data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(f\"Processing {bert_model}...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(bert_model)\n",
    "model = AutoModel.from_pretrained(bert_model, output_hidden_states=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_hidden_states_list = []\n",
    "# Process in batches\n",
    "for batch in np.array_split(np.array(X_train['preprocessed_text']), 10):\n",
    "    inputs = tokenizer(batch.tolist(), return_tensors=\"pt\", padding=True, truncation=True, max_length=30)\n",
    "    with torch.no_grad():\n",
    "    \n",
    "        outputs = model(**inputs)\n",
    "        # Correctly extract the last four hidden states\n",
    "        hidden_states = outputs.hidden_states[-5:]  # This is a tuple of the last four layers\n",
    "        # Concatenate the last four layers for each token across the batch\n",
    "        concatenated_layers = torch.cat([hidden_states[i] for i in range(5)], dim=-1)  # Now shape is [batch_size, seq_length, 4*hidden_size]\n",
    "\n",
    "        \n",
    "    train_hidden_states_list.append(concatenated_layers)\n",
    "    ##### updated code end\n",
    "  \n",
    "   \n",
    "## Concatenate along the batch dimension\n",
    "train_hidden_states = torch.cat(train_hidden_states_list, dim=0)\n",
    "\n",
    "## Code update start for train\n",
    "tensor = torch.tensor(numerical_features.values, dtype=torch.float32)\n",
    "batch_size = tensor.shape[0]\n",
    "\n",
    "# Reshape tensor to match batch size\n",
    "tensor = tensor.view(batch_size, -1)\n",
    "\n",
    "train_hidden_states_upd = torch.cat([train_hidden_states, tensor.unsqueeze(1).repeat(1, 30, 1)], dim=-1)\n",
    "## Code update end for train\n",
    "\n",
    "\n",
    "\n",
    "# Optionally convert to numpy if needed\n",
    "# train_hidden_states = train_hidden_states.numpy()\n",
    "print(train_hidden_states_upd.shape)\n",
    "test_hidden_states_list = []\n",
    "# Process in batches\n",
    "for batch in np.array_split(np.array(X_test['preprocessed_text']), 20):\n",
    "    inputs = tokenizer(batch.tolist(), return_tensors=\"pt\", padding=True, truncation=True, max_length=30)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        # Correctly extract the last four hidden states\n",
    "        hidden_states = outputs.hidden_states[-5:]  # This is a tuple of the last four layers\n",
    "        # Concatenate the last four layers for each token across the batch\n",
    "        concatenated_layers = torch.cat([hidden_states[i] for i in range(5)], dim=-1)  # Now shape is [batch_size, seq_length, 4*hidden_size]\n",
    "    test_hidden_states_list.append(concatenated_layers)\n",
    "# Concatenate along the batch dimension\n",
    "test_hidden_states = torch.cat(test_hidden_states_list, dim=0)\n",
    "\n",
    "###Code update start###\n",
    "tensor_test = torch.tensor(numerical_features_test.values, dtype=torch.float32)\n",
    "batch_size = tensor_test.shape[0]\n",
    "\n",
    "# Reshape tensor to match batch size\n",
    "tensor_test = tensor_test.view(batch_size, -1)\n",
    "\n",
    "test_hidden_states_upd = torch.cat([test_hidden_states, tensor_test.unsqueeze(1).repeat(1, 30, 1)], dim=-1)\n",
    "\n",
    "\n",
    "# Optionally convert to numpy if needed\n",
    "# train_hidden_states = train_hidden_states.numpy()\n",
    "print(test_hidden_states_upd.shape)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)  # Assuming classification task\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.long)\n",
    "# Create TensorDataset instances\n",
    "train_dataset = TensorDataset(train_hidden_states_upd, y_train_tensor)\n",
    "test_dataset = TensorDataset(test_hidden_states_upd, y_test_tensor)\n",
    "# Create DataLoader instances\n",
    "batch_size = 32  # Adjust based on your preference and system capability\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc6f554-ac98-4544-965c-9ecfe5b5a0b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17c9281a-a5ba-4155-86da-32c4070cb7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class CustomCNN(nn.Module):\n",
    "    # 5 different sizes of kernels with 32 times each for 1d data as input\n",
    "    def __init__(self, num_filters=32, filter_sizes=[1,2, 3, 4, 5], num_classes=2):\n",
    "        super(CustomCNN, self).__init__()\n",
    "        self.conv_layers = nn.ModuleList()\n",
    "        feature_size = 3878  # 4*768+numericals\n",
    "        for size in filter_sizes:\n",
    "            # Assuming the input is reshaped to [batch_size, 1, seq_length, 3072] before being passed to the model\n",
    "            conv_layer = nn.Conv2d(in_channels=1,\n",
    "                                   out_channels=num_filters,\n",
    "                                   kernel_size=(size, feature_size),\n",
    "                                   stride=(1, feature_size))\n",
    "            self.conv_layers.append(conv_layer)\n",
    "        self.linear = nn.Linear(num_filters * len(filter_sizes), num_classes)\n",
    "    def forward(self, x):\n",
    "        # Reshape x to add a channel dimension ([batch_size, seq_length, 3072] -> [batch_size, 1, seq_length, 3072])\n",
    "        x = x.unsqueeze(1)  # Add channel dimension\n",
    "        conv_outputs = []\n",
    "        for conv_layer in self.conv_layers:\n",
    "            conv_out = F.relu(conv_layer(x))\n",
    "            # Since our convolution outputs will have a reduced \"height\", we pool over the entire height\n",
    "            conv_out = F.max_pool2d(conv_out, kernel_size=(conv_out.size(2), 1))\n",
    "            conv_outputs.append(conv_out.squeeze(2))  # Remove the dimension of size 1 after pooling\n",
    "        concat_out = torch.cat(conv_outputs, dim=1)\n",
    "        flat_out = torch.flatten(concat_out, start_dim=1)\n",
    "        output = self.linear(flat_out)\n",
    "        return output\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2aa31244-d3c3-4e93-bbf2-8a4fa60d8394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomCNN(\n",
      "  (conv_layers): ModuleList(\n",
      "    (0): Conv2d(1, 32, kernel_size=(1, 3878), stride=(1, 3878))\n",
      "    (1): Conv2d(1, 32, kernel_size=(2, 3878), stride=(1, 3878))\n",
      "    (2): Conv2d(1, 32, kernel_size=(3, 3878), stride=(1, 3878))\n",
      "    (3): Conv2d(1, 32, kernel_size=(4, 3878), stride=(1, 3878))\n",
      "    (4): Conv2d(1, 32, kernel_size=(5, 3878), stride=(1, 3878))\n",
      "  )\n",
      "  (linear): Linear(in_features=160, out_features=2, bias=True)\n",
      ")\n",
      "Epoch [1/30], Train Loss: 0.5614, Test Loss: 0.5310, Test Accuracy: 0.7344, AUC ROC: 0.7635\n",
      "Epoch [2/30], Train Loss: 0.4667, Test Loss: 0.4912, Test Accuracy: 0.7344, AUC ROC: 0.7810\n",
      "Epoch [3/30], Train Loss: 0.4135, Test Loss: 0.4781, Test Accuracy: 0.7812, AUC ROC: 0.7985\n",
      "Epoch [4/30], Train Loss: 0.3756, Test Loss: 0.4595, Test Accuracy: 0.7969, AUC ROC: 0.8073\n",
      "Epoch [5/30], Train Loss: 0.3496, Test Loss: 0.4478, Test Accuracy: 0.7969, AUC ROC: 0.8210\n",
      "Epoch [6/30], Train Loss: 0.3325, Test Loss: 0.4487, Test Accuracy: 0.7969, AUC ROC: 0.8198\n",
      "Epoch [7/30], Train Loss: 0.3114, Test Loss: 0.4392, Test Accuracy: 0.7812, AUC ROC: 0.8223\n",
      "Epoch [8/30], Train Loss: 0.2966, Test Loss: 0.4371, Test Accuracy: 0.7812, AUC ROC: 0.8235\n",
      "Epoch [9/30], Train Loss: 0.2859, Test Loss: 0.4407, Test Accuracy: 0.7969, AUC ROC: 0.8223\n",
      "Epoch [10/30], Train Loss: 0.2742, Test Loss: 0.4326, Test Accuracy: 0.7812, AUC ROC: 0.8210\n",
      "Epoch [11/30], Train Loss: 0.2621, Test Loss: 0.4364, Test Accuracy: 0.7812, AUC ROC: 0.8198\n",
      "Epoch [12/30], Train Loss: 0.2551, Test Loss: 0.4446, Test Accuracy: 0.7969, AUC ROC: 0.8160\n",
      "Epoch [13/30], Train Loss: 0.2434, Test Loss: 0.4319, Test Accuracy: 0.7656, AUC ROC: 0.8185\n",
      "Epoch [14/30], Train Loss: 0.2377, Test Loss: 0.4391, Test Accuracy: 0.7812, AUC ROC: 0.8223\n",
      "Epoch [15/30], Train Loss: 0.2297, Test Loss: 0.4429, Test Accuracy: 0.8125, AUC ROC: 0.8173\n",
      "Epoch [16/30], Train Loss: 0.2256, Test Loss: 0.4449, Test Accuracy: 0.7969, AUC ROC: 0.8135\n",
      "Epoch [17/30], Train Loss: 0.2162, Test Loss: 0.4323, Test Accuracy: 0.7812, AUC ROC: 0.8285\n",
      "Epoch [18/30], Train Loss: 0.2125, Test Loss: 0.4369, Test Accuracy: 0.7812, AUC ROC: 0.8185\n",
      "Epoch [19/30], Train Loss: 0.2054, Test Loss: 0.4460, Test Accuracy: 0.8125, AUC ROC: 0.8173\n",
      "Epoch [20/30], Train Loss: 0.1980, Test Loss: 0.4373, Test Accuracy: 0.7812, AUC ROC: 0.8173\n",
      "Epoch [21/30], Train Loss: 0.1938, Test Loss: 0.4343, Test Accuracy: 0.7812, AUC ROC: 0.8248\n",
      "Epoch [22/30], Train Loss: 0.1890, Test Loss: 0.4431, Test Accuracy: 0.8125, AUC ROC: 0.8260\n",
      "Epoch [23/30], Train Loss: 0.1833, Test Loss: 0.4369, Test Accuracy: 0.7812, AUC ROC: 0.8235\n",
      "Epoch [24/30], Train Loss: 0.1786, Test Loss: 0.4399, Test Accuracy: 0.7969, AUC ROC: 0.8273\n",
      "Epoch [25/30], Train Loss: 0.1779, Test Loss: 0.4410, Test Accuracy: 0.7969, AUC ROC: 0.8260\n",
      "Epoch [26/30], Train Loss: 0.1722, Test Loss: 0.4416, Test Accuracy: 0.8125, AUC ROC: 0.8248\n",
      "Epoch [27/30], Train Loss: 0.1680, Test Loss: 0.4413, Test Accuracy: 0.7969, AUC ROC: 0.8285\n",
      "Epoch [28/30], Train Loss: 0.1624, Test Loss: 0.4348, Test Accuracy: 0.7812, AUC ROC: 0.8260\n",
      "Epoch [29/30], Train Loss: 0.1602, Test Loss: 0.4385, Test Accuracy: 0.7969, AUC ROC: 0.8285\n",
      "Epoch [30/30], Train Loss: 0.1559, Test Loss: 0.4438, Test Accuracy: 0.7969, AUC ROC: 0.8273\n"
     ]
    }
   ],
   "source": [
    "   \n",
    "model = CustomCNN()\n",
    "print(model)\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "# Assuming 'model' is already defined and correctly configured for your task\n",
    "# Define the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=2e-5)\n",
    "# Define the loss function\n",
    "criterion = nn.CrossEntropyLoss()  # For binary classification with 2 output units\n",
    "# Number of training epochs\n",
    "num_epochs = 30\n",
    "# Move model to the appropriate device (e.g., GPU if available)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model in training mode\n",
    "    train_loss = 0.0\n",
    "    for inputs1,labels in train_loader:  # Iterate over the training dataset\n",
    "        inputs, labels = inputs1.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "        outputs = model(inputs)  # Forward pass\n",
    "        loss = criterion(outputs, labels)  # Calculate the loss\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Update the parameters\n",
    "        train_loss += loss.item() * inputs.size(0)  # Accumulate the training loss\n",
    "    train_loss = train_loss / len(train_loader.dataset)  # Calculate average training loss\n",
    "    model.eval()  # Set the model in evaluation mode\n",
    "    test_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "    with torch.no_grad():  # Disable gradient calculation during validation\n",
    "        for inputs1, labels in test_loader:  # Iterate over the test dataset\n",
    "            inputs, labels = inputs1.to(device), labels.to(device)\n",
    "            outputs = model(inputs)  # Forward pass\n",
    "            loss = criterion(outputs, labels)  # Calculate the loss\n",
    "            test_loss += loss.item() * inputs.size(0)  # Accumulate the test loss\n",
    "            _, predicted = torch.max(outputs.data, 1)  # Get the predicted class\n",
    "            correct_predictions += (predicted == labels).sum().item()  # Count correct predictions\n",
    "            # Store probabilities (use softmax outputs if available) and true labels for ROC AUC calculation\n",
    "            probs = nn.functional.softmax(outputs, dim=1)[:, 1]  # Assuming your model outputs raw logits\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(probs.cpu().numpy())\n",
    "    test_loss = test_loss / len(test_loader.dataset)  # Calculate average test loss\n",
    "    accuracy = correct_predictions / len(test_loader.dataset)  # Calculate test accuracy\n",
    "    auc_roc_score = roc_auc_score(all_labels, all_predictions)  # Calculate AUC ROC score\n",
    "    # Print the epoch, training loss, test loss, test accuracy, and AUC ROC score\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Test Accuracy: {accuracy:.4f}, AUC ROC: {auc_roc_score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "750fd52c-b8e1-4716-96e1-981d9d257507",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataframe_values\n",
      "dataframe_values\n",
      "dataframe_values\n",
      "dataframe_values\n",
      "dataframe_values\n",
      "dataframe_values\n",
      "dataframe_values\n",
      "dataframe_values\n"
     ]
    }
   ],
   "source": [
    " for inputs, labels,x in merged_train_loader:\n",
    "        print(x)"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "lcc_arn": "arn:aws:sagemaker:us-east-1:306369642730:studio-lifecycle-config/install-wr"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
